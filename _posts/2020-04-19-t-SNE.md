--- 
title: "A t-SNE Implementation with tunable emphasis on global data manifold structure"
date: 2020-04-19
layout: "single"
permalink: /t-SNE/
tagline: ""
mathjax: "true"
---

### A more flexible similarity metric than the students-t distribution
My "t-SNE" [repository](https://github.com/M-Lin-DM/Dimensionality-Reduction) includes matlab functions which implement customized versions of t-SNE. The main difference from the original paper is the use of a different similarity metric in the embedding space. This function allows you to more intuitively tune and explore the embedded result.

For all scripts I use a modified similarity function (as opposed to the student's t distribution) for computing the similarity of two points in the lower dimensional embedding. This function can be tuned more intuitively using the `bulge` and `fan` parameters. If `d` is the distance between two points, their similarity is computed as
```matlab
(1+d.^bulge).^-fan
```
Tuning these parameters can produce dramatically different results. By changing `fan` one can adjust the thickness of the function's tails. Thicker tails will grant more similarity to pairs of points which are futher apart. You can therefore adjust the priority towards preserving large-scale structure of the data. With thinner tails, the large scale structure becomes more flexible, and the algorithm will prioritize accurately representing local structure. That is points, which are close in the high dimesional space are guaranteed to be close in the embedding, but points which are far apart can be either close or far in the embedding. 

### Swiss roll dataset
For all comparisons below I use the 3D "swiss roll" dataset and reduce it into 2D. As t-SNE is an iterative process, I also use the exact same initial condition: points are drawn from a bivariate normal distribution in 2D.

![im](/images/tSNE_figures/swroll.png)


# tSNE_simple.m

This modified t-SNE skips the computation of neighborhood sizes Ïƒ, and instead uses the same neighborhood size for each point. This is equivalent to computing a similarity matrix using a radial basis function/kernel and a euclidean distance metric.

![im](/images/tSNE_figures/universal_sigma_tsne_simple.png)

# tSNE_perplexity.m

This implementation is very close to the original paper [1]. A unique neighborhood size is optimized for each point. The function takes the perplexity `perp` as an argument.

![im](/images/tSNE_figures/perp1.png)
![im](/images/tSNE_figures/perp2.png)
![im](/images/tSNE_figures/perp3.png)
![im](/images/tSNE_figures/perp4.png)

# tSNE_Prefab_similarityMatrix.m

This function allows you to perform a t-SNE like dimensionality reduction, but skipping the computation of similarities in the original high-dimensional space. Instead you can provide a prefabricated similarity matrix `P` and the algorithm will pick up from that point as normal.

Here I computed a similarity matrix from the raw swiss roll data and then fed that to tSNE_Prefab_similarityMatrix.m
```matlab
dat=load('swissroll'); dat=dat.dat; 
P=squareform(pdist(dat,'euclidean'));
G=@(d,sig) exp(-d.^2/(2*sig^2));
W=G(P,1.5);
emb=tSNE_Prefab_similarityMatrix(W,2,100);
```
![im](/images/tSNE_figures/prefabW.png)

# Effect of data manifold shape
Below I vary the height of the swiss roll given to t-SNE (length of data along z axis), and fix the perplexity at 1.7. There is a transition as embedding captures more of the variation along the z-axis. At the same time, the embedding begins to not physically separate points at different lengths along the roll, creating false overlap.

![im](/images/tSNE_figures/h4.png)
![im](/images/tSNE_figures/h8.png)
![im](/images/tSNE_figures/h12.png)
![im](/images/tSNE_figures/h16.png)



# References
1. Maaten, Laurens van der, and Geoffrey Hinton. "Visualizing data using t-SNE." Journal of machine learning research 9.Nov (2008): 2579-2605.